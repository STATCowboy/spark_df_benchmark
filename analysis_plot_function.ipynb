{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>element_count</th>\n",
       "      <th>column_count</th>\n",
       "      <th>array_time</th>\n",
       "      <th>pandas_df_time</th>\n",
       "      <th>pandas_df_compute</th>\n",
       "      <th>spark_df_time</th>\n",
       "      <th>spark_df_compute</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.021119</td>\n",
       "      <td>0.481810</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.024482</td>\n",
       "      <td>0.442082</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.047411</td>\n",
       "      <td>0.559718</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.208266</td>\n",
       "      <td>2.635492</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.017645</td>\n",
       "      <td>0.342826</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   element_count  column_count  array_time  pandas_df_time  pandas_df_compute  \\\n",
       "4             10             1    0.000018        0.000093           0.000277   \n",
       "5            100            10    0.000011        0.000052           0.000160   \n",
       "6           1000           100    0.000027        0.000096           0.000435   \n",
       "7          10000          1000    0.000164        0.000091           0.025667   \n",
       "8            100             1    0.000025        0.000052           0.000286   \n",
       "\n",
       "   spark_df_time  spark_df_compute  row_count  \n",
       "4       0.021119          0.481810       10.0  \n",
       "5       0.024482          0.442082       10.0  \n",
       "6       0.047411          0.559718       10.0  \n",
       "7       0.208266          2.635492       10.0  \n",
       "8       0.017645          0.342826      100.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df=pd.read_csv('results_corr.csv')\n",
    "corr_df=corr_df.drop(corr_df.columns[0], axis=1)\n",
    "corr_df=corr_df.dropna()\n",
    "corr_df['row_count']=corr_df['element_count']/corr_df['column_count']\n",
    "corr_df.sort_values(by=['row_count', 'column_count'])\n",
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>array_time</th>\n",
       "      <th>column_count</th>\n",
       "      <th>element_count</th>\n",
       "      <th>pandas_df_compute</th>\n",
       "      <th>pandas_df_time</th>\n",
       "      <th>spark_df_compute</th>\n",
       "      <th>spark_df_time</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.130022</td>\n",
       "      <td>0.013988</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.152254</td>\n",
       "      <td>0.019682</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.850829</td>\n",
       "      <td>0.033399</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>7.937093</td>\n",
       "      <td>0.154767</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   array_time  column_count  element_count  pandas_df_compute  pandas_df_time  \\\n",
       "0    0.000010             1              1           0.000111        0.000052   \n",
       "1    0.000020            10             10           0.000255        0.000094   \n",
       "2    0.000018           100            100           0.000644        0.000102   \n",
       "3    0.000020          1000           1000           0.002150        0.000053   \n",
       "4    0.000010             1             10           0.000107        0.000052   \n",
       "\n",
       "   spark_df_compute  spark_df_time  row_count  \n",
       "0          0.130022       0.013988        1.0  \n",
       "1          0.152254       0.019682        1.0  \n",
       "2          0.850829       0.033399        1.0  \n",
       "3          7.937093       0.154767        1.0  \n",
       "4          0.098161       0.012703       10.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df=pd.read_csv('results_mean.csv')\n",
    "mean_df=mean_df.drop(mean_df.columns[0], axis=1)\n",
    "mean_df=mean_df.dropna()\n",
    "mean_df['row_count']=mean_df['element_count']/mean_df['column_count']\n",
    "mean_df.sort_values(by=['row_count', 'column_count'])\n",
    "mean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Stacked Line Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa763a6c6a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=corr_df\n",
    "fig, ax=plt.subplots(1, 2, sharey=True)\n",
    "for each_column_ct in df['column_count'].unique(): \n",
    "    sub_df=df[df['column_count']==each_column_ct]\n",
    "    ax[0].plot(np.log(sub_df['row_count']), \n",
    "               np.log(sub_df['pandas_df_compute']), label=each_column_ct)\n",
    "for each_column_ct in df['column_count'].unique(): \n",
    "    sub_df=df[df['column_count']==each_column_ct]\n",
    "    ax[1].plot(np.log(sub_df['row_count']), \n",
    "             np.log(sub_df['spark_df_compute']), label=each_column_ct)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "df=mean_df\n",
    "fig=plt.figure()\n",
    "ax=plt.axes(projection='3d')\n",
    "ax.scatter3D(np.log(df['row_count']),\n",
    "             np.log(df['column_count']), \n",
    "             np.log(df['pandas_df_compute']), \n",
    "             c='tab:red')\n",
    "ax.scatter3D(np.log(df['row_count']),\n",
    "             np.log(df['column_count']), \n",
    "             np.log(df['spark_df_compute']), \n",
    "             c='tab:blue')\n",
    "\n",
    "all_row_counts=df['row_count'].unique()\n",
    "all_column_counts=df['column_count'].unique()\n",
    "xlabels_exp=sorted(all_row_counts)\n",
    "xlabels_exp_red=[label for idx, label in enumerate(xlabels_exp) if idx%2==0]\n",
    "xticks_locs=np.log(xlabels_exp_red)\n",
    "xticks_labels=xlabels_exp_red\n",
    "ylabels_exp=sorted(all_column_counts)\n",
    "yticks_locs=np.log(ylabels_exp)\n",
    "yticks_labels=ylabels_exp\n",
    "min_time=df[['spark_df_compute', 'pandas_df_compute']].min().min()\n",
    "max_time=df[['spark_df_compute', 'pandas_df_compute']].max().max()\n",
    "zlabels_log=np.linspace(np.log(min_time), np.log(max_time), 5)\n",
    "zticks_locs=zlabels_log\n",
    "zticks_labels=np.exp(zlabels_log).round(2)\n",
    "\n",
    "ax.set_xlabel('row_count')\n",
    "ax.set_xticks(xticks_locs)\n",
    "ax.set_xticklabels(xticks_labels)\n",
    "ax.set_ylabel('column_count')\n",
    "ax.set_yticks(yticks_locs)\n",
    "ax.set_yticklabels(yticks_labels)\n",
    "ax.set_zlabel('compute_time (s)')\n",
    "ax.set_zticks(zticks_locs)\n",
    "ax.set_zticklabels(zticks_labels)\n",
    "ax.set_title('DataFrame Mean Computation Time (s)', pad=25)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Surface Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Model to Draw Plane - Pandas & Spark\n",
    "#### 2) Meshgrid for Plane - Pandas & Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def get_plane(input_df, degree, planes_count): \n",
    "    # get grid projection plane\n",
    "    poly=PolynomialFeatures(degree=degree)\n",
    "    x=np.log(input_df[['row_count', 'column_count']])\n",
    "    transformed_x=poly.fit_transform(x)\n",
    "    all_row_counts=input_df['row_count'].unique()\n",
    "    all_column_counts=input_df['column_count'].unique()\n",
    "    x_1=np.linspace(np.log(all_row_counts.min()), np.log(all_row_counts.max()), planes_count)\n",
    "    x_2=np.linspace(np.log(all_column_counts.min()), np.log(all_column_counts.max()), planes_count)\n",
    "    X_1, X_2=np.meshgrid(x_1, x_2)\n",
    "    r1, r2=X_1.flatten(), X_2.flatten()\n",
    "    r1, r2=r1.reshape(-1, 1), r2.reshape(-1, 1)\n",
    "    grid=np.hstack([r1, r2])\n",
    "    transformed_grid=poly.transform(grid)\n",
    "\n",
    "    # fit regression for Pandas compute\n",
    "    pandas_compute=np.log(input_df['pandas_df_compute'])\n",
    "    pandas_lr_poly=LinearRegression()\n",
    "    pandas_lr_poly.fit(transformed_x, pandas_compute)\n",
    "    print(f'Pandas R^2 Score: {pandas_lr_poly.score(transformed_x, pandas_compute)}')\n",
    "    \n",
    "    # infer plane for Pandas compute\n",
    "    pandas_results_poly=pandas_lr_poly.predict(transformed_x)\n",
    "    pandas_z=pandas_lr_poly.predict(transformed_grid)\n",
    "    pandas_Z=pandas_z.reshape(-1, planes_count)\n",
    "    \n",
    "    # get regression for Spark compute\n",
    "    spark_compute=np.log(input_df['spark_df_compute'])\n",
    "    spark_lr_poly=LinearRegression()\n",
    "    spark_lr_poly.fit(transformed_x, spark_compute)\n",
    "    print(f'Spark R^2 Score: {spark_lr_poly.score(transformed_x, spark_compute)}')\n",
    "\n",
    "    # infer plane for Spark compute\n",
    "    spark_results_poly=spark_lr_poly.predict(transformed_x)\n",
    "    spark_z=spark_lr_poly.predict(transformed_grid)\n",
    "    spark_Z=spark_z.reshape(-1, planes_count)\n",
    "    \n",
    "    # get X, Y, Z labels \n",
    "    xlabels_exp=sorted(all_row_counts)\n",
    "    xlabels_exp_red=[label for idx, label in enumerate(xlabels_exp) if idx%2==0]\n",
    "    xticks_locs=np.log(xlabels_exp_red)\n",
    "    xticks_labels=xlabels_exp_red\n",
    "    ylabels_exp=sorted(all_column_counts)\n",
    "    yticks_locs=np.log(ylabels_exp)\n",
    "    yticks_labels=ylabels_exp\n",
    "    min_time=input_df[['spark_df_compute', 'pandas_df_compute']].min().min()\n",
    "    max_time=input_df[['spark_df_compute', 'pandas_df_compute']].max().max()\n",
    "    zlabels_log=np.linspace(np.log(min_time), np.log(max_time), 5)\n",
    "    zticks_locs=zlabels_log\n",
    "    zticks_labels=np.exp(zlabels_log).round(2)\n",
    "\n",
    "    return X_1, X_2, pandas_Z, spark_Z, xticks_locs, xticks_labels, yticks_locs, yticks_labels, zticks_locs, zticks_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Pandas R^2 Score: 0.9919412306340483\n",
      "Spark R^2 Score: 0.9691618615469142\n",
      "Pandas R^2 Score: 0.9483225634815378\n",
      "Spark R^2 Score: 0.9624447516279816\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "fig=plt.figure(figsize=(10, 5))\n",
    "#====first plot====\n",
    "ax_corr=fig.add_subplot(1, 2, 1, projection='3d')\n",
    "X_1, X_2, pandas_Z, spark_Z, xticks_locs, xticks_labels, yticks_locs, yticks_labels, zticks_locs, zticks_labels=get_plane(corr_df, 2, 20)\n",
    "\n",
    "ax_corr.plot_wireframe(X_1,\n",
    "                X_2, \n",
    "                spark_Z, \n",
    "                color='tab:blue', \n",
    "                label='Spark DataFrame')\n",
    "ax_corr.plot_wireframe(X_1,\n",
    "                X_2, \n",
    "                pandas_Z, \n",
    "                color='tab:red', \n",
    "                label='Pandas DataFrame')\n",
    "\n",
    "ax_corr.set_xlabel('row_count')\n",
    "ax_corr.set_xticks(xticks_locs)\n",
    "ax_corr.set_xticklabels(xticks_labels)\n",
    "ax_corr.set_ylabel('column_count')\n",
    "ax_corr.set_yticks(yticks_locs)\n",
    "ax_corr.set_yticklabels(yticks_labels)\n",
    "ax_corr.set_zlabel('compute_time (s)')\n",
    "ax_corr.set_zticks(zticks_locs)\n",
    "ax_corr.set_zticklabels(zticks_labels)\n",
    "ax_corr.set_title('DataFrame Corr Computation Time (s)', pad=25)\n",
    "\n",
    "#====second plot====\n",
    "ax_mean=fig.add_subplot(1, 2, 2, projection='3d')\n",
    "X_1, X_2, pandas_Z, spark_Z, xticks_locs, xticks_labels, yticks_locs, yticks_labels, zticks_locs, zticks_labels=get_plane(mean_df, 2, 20)\n",
    "\n",
    "ax_mean.plot_wireframe(X_1,\n",
    "                X_2, \n",
    "                spark_Z, \n",
    "                color='tab:blue', \n",
    "                label='Spark DataFrame')\n",
    "ax_mean.plot_wireframe(X_1,\n",
    "                X_2, \n",
    "                pandas_Z, \n",
    "                color='tab:red', \n",
    "                label='Pandas DataFrame')\n",
    "\n",
    "ax_mean.set_xlabel('row_count')\n",
    "ax_mean.set_xticks(xticks_locs)\n",
    "ax_mean.set_xticklabels(xticks_labels)\n",
    "ax_mean.set_ylabel('column_count')\n",
    "ax_mean.set_yticks(yticks_locs)\n",
    "ax_mean.set_yticklabels(yticks_labels)\n",
    "ax_mean.set_zlabel('compute_time (s)')\n",
    "ax_mean.set_zticks(zticks_locs)\n",
    "ax_mean.set_zticklabels(zticks_labels)\n",
    "ax_mean.set_title('DataFrame Mean Computation Time (s)', pad=25)\n",
    "\n",
    "col1_patch = mpatches.Patch(color='tab:blue', label='Spark DataFrame')\n",
    "col2_patch = mpatches.Patch(color='tab:red', label='Pandas DataFrame')\n",
    "plt.legend(handles=[col1_patch, col2_patch])\n",
    "\n",
    "# # create movie\n",
    "# for ii in range(0,360,1):\n",
    "#     if ii>=180 and ii<=270 and ii%3==0: \n",
    "#         ax_corr.view_init(elev=10., azim=ii)\n",
    "#         ax_mean.view_init(elev=10., azim=ii)\n",
    "#         plt.savefig(\"movie/movie%d.png\" % ii)\n",
    "#     elif (ii<=180 or ii>=270) and ii%10==0: \n",
    "#         ax_corr.view_init(elev=10., azim=ii)\n",
    "#         ax_mean.view_init(elev=10., azim=ii)\n",
    "#         plt.savefig(\"movie/movie%d.png\" % ii)\n",
    "\n",
    "#240 puts 0, 0 on left\n",
    "# ax_corr.view_init(elev=5, azim=240)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>column_count</th>\n",
       "      <th>pandas_df_compute</th>\n",
       "      <th>spark_df_compute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.281180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.056344</td>\n",
       "      <td>2.433687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.898498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.066983</td>\n",
       "      <td>1.903459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>7.524165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_count  column_count  pandas_df_compute  spark_df_compute\n",
       "21    100000.0            10           0.003276          0.281180\n",
       "22    100000.0           100           0.056344          2.433687\n",
       "23   1000000.0             1           0.001849          0.898498\n",
       "24   1000000.0            10           0.066983          1.903459\n",
       "25  10000000.0             1           0.017181          7.524165"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df[['row_count', 'column_count', 'pandas_df_compute', 'spark_df_compute']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_corr.view_init()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
